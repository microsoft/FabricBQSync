{"cells":[{"cell_type":"markdown","source":["## Install Required Supporting Libraries"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b05d0b4f-55e4-4247-9872-d4b99eed02c9"},{"cell_type":"code","source":["%pip install --q semantic-link"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":true},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"247c8378-157f-4c17-bf24-db603bce433b"},{"cell_type":"markdown","source":["## BQ Sync Python Package\n","If you are not going to leverage an environment, the BQ Sync package needs to be installed at runtime. \n","\n","<strong>Options for Loading/Using the BQ Sync Package</strong>\n","1. Runtime from OneLake (stable): <br />\n","    <code>%pip install /lakehouse/default/Files/BQ_Sync_Process/libs/FabricSync-0.1.0-py3-none-any.whl</code>\n","2. Runtime from GitHub (latest version): <br/>\n","    <code>%pip install https://github.com/microsoft/FabricBQSync/raw/main/Packages/FabricSync/dist/FabricSync-0.1.0-py3-none-any.whl</code>\n","3. From Spark Environment \n","\n","<strong>Please note that if you are scheduling this notebook to run from a pipeline, you must provide the <code>_inlineInstallationEnabled</code> parameter to the pipeline for pip install support.</strong>"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a39ef847-5d76-4541-96a6-4889c29ca5c5"},{"cell_type":"code","source":["%pip install --upgrade --force-reinstall https://github.com/microsoft/FabricBQSync/raw/main/Packages/FabricSync/dist/FabricSync-0.1.0-py3-none-any.whl"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":true},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"200b828e-cc69-49b9-909f-a2ec016e799e"},{"cell_type":"code","source":["from FabricSync.FabricAPI import *\n","from FabricSync.DeltaStorageInventory import *"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":true},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f33e6105-6cc6-4f4d-a5f3-9eb1aec77a7a"},{"cell_type":"markdown","source":["## Configuration for the OneLake Delta Inventory"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e327dde3-bb5a-4037-bc77-faa4cdc03433"},{"cell_type":"code","source":["lakehouse_name = \"DW\" #The Lakehouse you want to inventory\n","\n","metadata_lakehouse = \"Sync_Metadata\" #The Lakehouse were the inventory output will be stored\n","parallelism = 5 #Degree of parallelism to use for the lakehouse inventory process\n","track_history = False #Track inventory history overtime (you must account for this history when running queries)\n","async_process = True #Process the lakehouse inventory asynchronously in parallel"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7f4462db-f605-4747-9c22-29ca85450536"},{"cell_type":"code","source":["fabric_api = FabricAPIUtil()\n","workspace_id = fabric_api.get_workspace_id()\n","lakehouse_id = fabric_api.get_lakehouse_id(workspace_id, lakehouse_name)\n","\n","fabric_api.get_or_create_lakehouse(workspace_id, metadata_lakehouse)\n","\n","delta_inventory = DeltaStorageInventory(session= spark, \\\n","    target_lakehouse=metadata_lakehouse, \n","    parallelism=parallelism,\n","    track_history=track_history,\n","    async_process=async_process)\n","\n","delta_inventory.run_onelake_lakehouse_catalog(workspace_id=workspace_id, \\\n","    lakehouse_id=lakehouse_id, \\\n","    lakehouse_name=lakehouse_name)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1002330b-2596-499e-83f2-90653797af35"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"65ff2942-8c71-46e8-82c1-ce46b70f1e36","default_lakehouse_name":"Sync_Metadata","default_lakehouse_workspace_id":"05fc0cfb-2425-4673-b2dc-6a7c0a3e1522"}}},"nbformat":4,"nbformat_minor":5}