{"cells":[{"cell_type":"markdown","source":["## <mark>Notebook must run in Environment with required libraries</mark>"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"788a1843-dd15-4742-9172-97d4eb6d8095"},{"cell_type":"markdown","source":["## BigQuery Spark Connector"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"5165ca45-cb7a-4223-a3c0-7a79279a2236"},{"cell_type":"code","source":["%%configure -f \n","{\n","    \"defaultLakehouse\": {\n","        \"name\": \"<<<METADATA_LAKEHOUSE_NAME>>>\",\n","        \"id\": \"<<<METADATA_LAKEHOUSE_ID>>>\",\n","        \"workspaceId\": \"<<<FABRIC_WORKSPACE_ID>>>\"\n","    }\n","}  "],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":true,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"aed6109e-d15f-4b72-8b48-fd909a85dc89"},{"cell_type":"markdown","source":["### BQ Spark Connector Optimizations"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"56a1defe-8ee5-4088-a7e5-59f46c8977a9"},{"cell_type":"code","source":["spark.conf.set(\"preferredMinParallelism\", 600) #This varies based on size of data and compute environment size\n","spark.conf.set(\"responseCompressionCodec\", \"RESPONSE_COMPRESSION_CODEC_LZ4\")\n","spark.conf.set(\"bqChannelPoolSize\", 80) #Match the number of executor cores for your configuration\n","\n","#For big data loads, set so that the BQ connection does not timeout\n","spark.conf.set(\"httpConnectTimeout\", 0)\n","spark.conf.set(\"httpReadTimeout\", 0)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"11d51d25-4645-477f-8e0b-819476c77863"},{"cell_type":"markdown","source":["# Config\n","The set-up process creates a minimal config file based on the parameters provided. \n","\n","You can update the config file at anytime and manually upload to an alternate path. \n","\n","Note: If you upload to a OneLake destination, it must be in the default Lakehouse and the <code>config_json_path</code> should point to the File API path (example: <code>/lakehouse/default/Files/myconfigfile.json</code>)."],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"da6ba8e3-9c37-49d2-8310-9fb0d0d4b3cb"},{"cell_type":"code","source":["config_json_path = \"<<<PATH_TO_USER_CONFIG>>>\"\n","schedule_type = \"AUTO\"\n","optimize_metadata = False"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}},"tags":["parameters"]},"id":"8c479e7b-120c-45b7-8363-adb7b9450ee6"},{"cell_type":"code","source":["from FabricSync.BQ.Sync import *"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"fde4eedb-e50c-467b-bf69-f27821ce125a"},{"cell_type":"markdown","source":["# Running BQ Sync"],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"b57f6f37-1733-4eee-a280-d67a2864ac13"},{"cell_type":"code","source":["bq_sync = BQSync(spark, config_json_path)\n","bq_sync.sync_metadata()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"d76a0dda-8c58-4eb6-85e8-c67e9ec86442"},{"cell_type":"markdown","source":["Before you continue, carefully evaluate your config for correctness.\n","\n","Once you run the next step, your load configuration is locked and cannot be changed without manually resetting the sync metadata and sync'd data."],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"1f126c75-f27d-4528-a5ac-069afc07aa9d"},{"cell_type":"code","source":["bq_sync.run_schedule(schedule_type=schedule_type, sync_metadata=False, optimize_metadata=optimize_metadata)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"a866194e-7779-4983-8b1e-7add099d7eb1"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"widgets":{},"synapse_widget":{"state":{},"version":"0.1"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"environment":{},"lakehouse":{"default_lakehouse":"8ba8f153-fd67-4cee-9301-8251decc0edb","default_lakehouse_name":"bq_metadata","default_lakehouse_workspace_id":"13f16035-d913-49ea-a01e-581fc9eca561"}}},"nbformat":4,"nbformat_minor":5}