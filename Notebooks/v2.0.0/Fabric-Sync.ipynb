{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5165ca45-cb7a-4223-a3c0-7a79279a2236",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## BigQuery Spark Connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed6109e-d15f-4b72-8b48-fd909a85dc89",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%%configure -f \n",
    "{\n",
    "    \"conf\": {\n",
    "        \"spark.jars\": \"<<<PATH_SPARK_BQ_JAR>>>\"\n",
    "    }\n",
    "}  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a02142-e2aa-4acf-b6d9-568f2ed7755e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## BQ Sync Python Package\n",
    "If you are not going to leverage an environment, the BQ Sync package needs to be installed at runtime. \n",
    "\n",
    "<strong>Please note that if you are scheduling this notebook to run from a pipeline, you must provide the <code>_inlineInstallationEnabled</code> parameter to the pipeline for pip install support.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e712fb75-3b1c-46ce-9026-e8fea610833d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install FabricSync>='<<<VERSION>>>' --quiet --disable-pip-version-check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a1defe-8ee5-4088-a7e5-59f46c8977a9",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### BQ Spark Connector Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d51d25-4645-477f-8e0b-819476c77863",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"readSessionCacheDurationMins\", \"1\")\n",
    "spark.conf.set(\"preferredMinParallelism\", 600) #This varies based on size of data and compute environment size\n",
    "spark.conf.set(\"responseCompressionCodec\", \"RESPONSE_COMPRESSION_CODEC_LZ4\")\n",
    "spark.conf.set(\"bqChannelPoolSize\", 80) #Match the number of executor cores for your configuration\n",
    "\n",
    "#For big data loads, set so that the BQ connection does not timeout\n",
    "spark.conf.set(\"httpConnectTimeout\", 0)\n",
    "spark.conf.set(\"httpReadTimeout\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ba8e3-9c37-49d2-8310-9fb0d0d4b3cb",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Config\n",
    "The set-up process creates a minimal config file based on the parameters provided. \n",
    "\n",
    "You can update the config file at anytime and manually upload to an alternate path. \n",
    "\n",
    "Note: If you upload to a OneLake destination, it must be in the default Lakehouse and the <code>config_json_path</code> should point to the File API path (example: <code>/lakehouse/default/Files/myconfigfile.json</code>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c479e7b-120c-45b7-8363-adb7b9450ee6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "config_json_path = \"<<<PATH_TO_USER_CONFIG>>>\"\n",
    "\n",
    "schedule_type = SyncScheduleType.AUTO\n",
    "optimize_metadata = False\n",
    "credential_provider = notebookutils.credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde4eedb-e50c-467b-bf69-f27821ce125a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from FabricSync.BQ.Sync import BQSync\n",
    "from FabricSync.BQ.Enum import SyncScheduleType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57f6f37-1733-4eee-a280-d67a2864ac13",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Running BQ Sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76a0dda-8c58-4eb6-85e8-c67e9ec86442",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "bq_sync = BQSync(config_json_path, credential_provider)\n",
    "bq_sync.sync_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f126c75-f27d-4528-a5ac-069afc07aa9d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Before you continue, carefully evaluate your config for correctness.\n",
    "\n",
    "Once you run the next step, your load configuration is locked and cannot be changed without manually resetting the sync metadata and sync'd data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a866194e-7779-4983-8b1e-7add099d7eb1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "bq_sync.run_schedule(schedule_type=schedule_type, sync_metadata=False, optimize_metadata=optimize_metadata)"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "environment": {},
   "lakehouse": {}
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
