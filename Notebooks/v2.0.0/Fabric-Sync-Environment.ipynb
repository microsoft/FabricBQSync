{"cells":[{"cell_type":"markdown","source":["# Fabric Sync Notebook"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9fb9c8d2-34e4-456f-829c-f424e0b17612"},{"cell_type":"markdown","source":["#### Fabric Sync Environment\n","\n","This notebook is configured to use the required libraries from a Fabric Spark Environment."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"5165ca45-cb7a-4223-a3c0-7a79279a2236"},{"cell_type":"code","source":["from FabricSync.BQ.Sync import BQSync\n","from FabricSync.BQ.Enum import SyncScheduleType"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6e647a75-f82c-4a52-9279-c6e41e8641c7"},{"cell_type":"markdown","source":["#### BQ Spark Connector Optimizations"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"56a1defe-8ee5-4088-a7e5-59f46c8977a9"},{"cell_type":"code","source":["spark.conf.set(\"readSessionCacheDurationMins\", \"1\")\n","spark.conf.set(\"preferredMinParallelism\", 600) #This varies based on size of data and compute environment size\n","spark.conf.set(\"responseCompressionCodec\", \"RESPONSE_COMPRESSION_CODEC_LZ4\")\n","spark.conf.set(\"bqChannelPoolSize\", 80) #Match the number of executor cores for your configuration\n","\n","#For big data loads, set so that the BQ connection does not timeout\n","spark.conf.set(\"httpConnectTimeout\", 0)\n","spark.conf.set(\"httpReadTimeout\", 0)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"11d51d25-4645-477f-8e0b-819476c77863"},{"cell_type":"markdown","source":["#### Config\n","The set-up process creates a minimal config file based on the parameters provided. \n","\n","Note: If you upload to a OneLake destination, it must be in the default Lakehouse and the <code>config_json_path</code> should point to the File API path (example: <code>/lakehouse/default/Files/myconfigfile.json</code>)."],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"da6ba8e3-9c37-49d2-8310-9fb0d0d4b3cb"},{"cell_type":"code","source":["config_json_path = \"<<<PATH_TO_USER_CONFIG>>>\"\n","schedule_type = SyncScheduleType.AUTO\n","optimize_metadata = False\n","credential_provider = notebookutils.credentials"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}},"tags":["parameters"]},"id":"8c479e7b-120c-45b7-8363-adb7b9450ee6"},{"cell_type":"markdown","source":["#### Running Fabric Sync"],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"b57f6f37-1733-4eee-a280-d67a2864ac13"},{"cell_type":"code","source":["bq_sync = BQSync(config_json_path, credential_provider)\n","metadata_result = bq_sync.sync_metadata()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"d76a0dda-8c58-4eb6-85e8-c67e9ec86442"},{"cell_type":"markdown","source":["Before you continue, carefully evaluate your config for correctness.\n","\n","Once you run the next step, your load configuration is locked and cannot be changed without manually resetting the sync metadata and sync'd data."],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"1f126c75-f27d-4528-a5ac-069afc07aa9d"},{"cell_type":"code","source":["if metadata_result:\n","    sync_result = bq_sync.run_schedule(schedule_type=schedule_type, sync_metadata=False, optimize_metadata=optimize_metadata)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"a866194e-7779-4983-8b1e-7add099d7eb1"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","language":"Python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"widgets":{},"synapse_widget":{"state":{},"version":"0.1"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"environment":{},"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}