{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6466d3e5-80a4-4a89-a9f8-74f49d6184a9",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Fabric Sync Installer\n",
    "\n",
    "Before you begin:\n",
    "1. <mark>Attached this notebook to a lakehouse within your workspace</mark>. \n",
    "    - If the workspace is new, create a new lakehouse for the Fabric Sync Metadata. For example: <code>BQSync_Metdata</code>\n",
    "2. Start your sessions and walk-through the installer notebook\n",
    "3. Update the environment configuration data as required below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50469d64-43fa-4a5e-99db-90e3ef79d1d6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"defaultLakehouse\": {\n",
    "        \"name\": \"<<MY METADATA WORKSPACE NAME>>\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7a4f49-058d-4216-97b0-d2f516441a6a",
   "metadata": {
    "editable": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "run_control": {
     "frozen": false
    }
   },
   "outputs": [],
   "source": [
    "%pip install FabricSync  --quiet --disable-pip-version-check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f2e921-5ddd-4b86-8e5f-8bc84aa76237",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Configure your Environment\n",
    "\n",
    "1. Loader Name - custom name for the data being loaded (ex: HR_Data_Sync, Sales_Data_Mirror)\n",
    "2. Metadata Lakehouse - name of the lakehouse used to drive the Fabric Sync process (Created if it doesn't exists)\n",
    "3. Target Lakehouse - name of the lakehouse where the Fabric Sync data will be landed (Created if it doesn't exists)\n",
    "4. GCP Project ID - the GCP billing project id that contains the in-scope dataset\n",
    "5. GCP Dataset - the BQ dataset id containing the data to be synced\n",
    "6. GCP Service Credential JSON File\n",
    "    - Upload your GCP Credential file to the attached lakehouse\n",
    "    - The <code>gcp_credential_path</code> is the File API Path to your JSON credential file <br />\n",
    "    Example: <code>/lakehouse/default/Files/my-credential-file.json\"</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56a8854-71f4-4880-8f2b-3ea7a53cb50e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"loader_name\":\"<<LOADER_NAME>>\",\n",
    "    \"metadata_lakehouse\":\"<<METADATA_LAKEHOUSE>>\",\n",
    "    \"target_lakehouse\":\"<<TARGET_LAKEHOUSE>>\",\n",
    "    \"gcp_project_id\":\"<<GCP_PROJECT_ID>>\",\n",
    "    \"gcp_dataset_id\":\"<<GCP DATASET>>\",\n",
    "    \"gcp_credential_path\":\"/lakehouse/default/Files/<<MY_SERVICE_CREDENTIAL>>.json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f82a6-3886-422c-a297-0354888f66f4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from FabricSync.FabricSetup import Installer\n",
    "\n",
    "token = mssparkutils.credentials.getToken(\"https://api.fabric.microsoft.com/\")\n",
    "\n",
    "installer = Installer(context=spark, api_token=token)\n",
    "installer.install(data)"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "environment": {},
   "lakehouse": {}
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
